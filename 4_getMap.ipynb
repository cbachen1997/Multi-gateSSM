{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"4_getMap.ipynb","provenance":[{"file_id":"1YJbzkN7M5076t7ddMiYt7aWdcziNkTRL","timestamp":1624879980086}],"collapsed_sections":["oYQIsncGeT5I","G93bxxMdxXGg","HTpQoHqcxZo0","zAAAizlSPp8l","A8dxvLxbZnyU"],"machine_shape":"hm","authorship_tag":"ABX9TyN6utR/IMrvf+DGRYtkzj3W"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"oYQIsncGeT5I"},"source":["#基础部分"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"flme12PO0Zeo","executionInfo":{"status":"ok","timestamp":1624675940261,"user_tz":-480,"elapsed":471,"user":{"displayName":"Boan Chen","photoUrl":"","userId":"13891223129202903233"}},"outputId":"41528c18-e0f3-4a4e-9830-928fdbf3fa18"},"source":["#挂载谷歌云盘\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","####google云盘授权#####\n","##每个notebook执行一次###\n","__author__='CBA'\n","from google.colab import drive\n","\n","#增加PyDrive操作库\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","#授权登录\n","auth.authenticate_user()\n","gauth=GoogleAuth()\n","gauth.credentials=GoogleCredentials.get_application_default()\n","drive=GoogleDrive(gauth)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cbH4ZfQGmXZ1"},"source":["# from __future__ import print_function, division\n","import tensorflow as tf\n","from sklearn.utils import shuffle\n","import tifffile as tiff\n","from tensorflow import keras as K\n","import tensorflow.keras.layers as L\n","import numpy as np\n","import os\n","import time\n","import h5py\n","import argparse \n","import random\n","import cv2\n","from tqdm import *\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.callbacks import LambdaCallback\n","# from keras.callbacks import TensorBoard\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.models import Model\n","from __future__ import print_function, division\n","from tensorflow.keras.layers import *\n","# from keras.layers import Dense,Dropout\n","from sklearn.utils import shuffle\n","# from keras.layers.core import Flatten\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import LeakyReLU\n","# from tensorflow.keras.layers.core import Lambda\n","from tensorflow.keras import backend as Kb\n","from collections import Counter\n","# from utils_1 import *"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G93bxxMdxXGg"},"source":["#模型"]},{"cell_type":"code","metadata":{"id":"Zk5aZa_3ytol"},"source":["def import_model(weightpath,train_para):\n","  ksize = 2 * r + 1\n","  inputshape = L.Input((ksize,ksize,hchn))\n","  \n","  output_feature = feature_extraction_CNN(inputshape,training_parameter=train_para, n_filters=64)\n","  logits = L.Dense(NUM_CLASS+1, activation = 'softmax')(output_feature)\n","  model = K.models.Model(inputshape, logits)\n","  adam = K.optimizers.Adam(lr=1e-3,beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01)\n","  # adam = K.optimizers.Adam(lr=1e-6)\n","  model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics=['acc'])\n","  model.load_weights(weightpath)\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"voMLypE3xZT6"},"source":["def tf_flatten(a):\n","  \"\"\"Flatten tensor\"\"\"\n","  return tf.reshape(a, [-1])\n","\n","\n","def tf_repeat(a, repeats, axis=0):\n","  \"\"\"TensorFlow version of np.repeat for 1D\"\"\"\n","  # https://github.com/tensorflow/tensorflow/issues/8521\n","  assert len(a.get_shape()) == 1\n","\n","  a = tf.expand_dims(a, -1)\n","  a = tf.tile(a, [1, repeats])\n","  a = tf_flatten(a)\n","  return a\n","\n","\n","def tf_repeat_2d(a, repeats):\n","  \"\"\"Tensorflow version of np.repeat for 2D\"\"\"\n","\n","  assert len(a.get_shape()) == 2\n","  a = tf.expand_dims(a, 0)\n","  a = tf.tile(a, [repeats, 1, 1])\n","  return a\n","\n","\n","def tf_map_coordinates(input, coords, order=1):\n","  \"\"\"Tensorflow verion of scipy.ndimage.map_coordinates\n","\n","  Note that coords is transposed and only 2D is supported\n","\n","  Parameters\n","  ----------\n","  input : tf.Tensor. shape = (s, s)\n","  coords : tf.Tensor. shape = (n_points, 2)\n","  \"\"\"\n","\n","  assert order == 1\n","\n","  coords_lt = tf.cast(tf.floor(coords), 'int32')\n","  #coords_rb = tf.cast(tf.ceil(coords), 'int32')\n","  coords_rb = tf.cast(tf.math.ceil(coords), 'int32')\n","  coords_lb = tf.stack([coords_lt[:, 0], coords_rb[:, 1]], axis=1)\n","  coords_rt = tf.stack([coords_rb[:, 0], coords_lt[:, 1]], axis=1)\n","\n","  vals_lt = tf.gather_nd(input, coords_lt)\n","  vals_rb = tf.gather_nd(input, coords_rb)\n","  vals_lb = tf.gather_nd(input, coords_lb)\n","  vals_rt = tf.gather_nd(input, coords_rt)\n","\n","  coords_offset_lt = coords - tf.cast(coords_lt, 'float32')\n","  vals_t = vals_lt + (vals_rt - vals_lt) * coords_offset_lt[:, 0]\n","  vals_b = vals_lb + (vals_rb - vals_lb) * coords_offset_lt[:, 0]\n","  mapped_vals = vals_t + (vals_b - vals_t) * coords_offset_lt[:, 1]\n","\n","  return mapped_vals\n","\n","\n","def sp_batch_map_coordinates(inputs, coords):\n","  \"\"\"Reference implementation for batch_map_coordinates\"\"\"\n","  coords = coords.clip(0, inputs.shape[1] - 1)\n","  mapped_vals = np.array([\n","      sp_map_coordinates(input, coord.T, mode='nearest', order=1)\n","      for input, coord in zip(inputs, coords)\n","  ])\n","  return mapped_vals\n","\n","\n","def tf_batch_map_coordinates(input, coords, order=1):\n","  \"\"\"Batch version of tf_map_coordinates\n","\n","  Only supports 2D feature maps\n","\n","  Parameters\n","  ----------\n","  input : tf.Tensor. shape = (b, s, s)\n","  coords : tf.Tensor. shape = (b, n_points, 2)\n","\n","  Returns\n","  -------\n","  tf.Tensor. shape = (b, s, s)\n","  \"\"\"\n","\n","  input_shape = tf.shape(input)\n","  batch_size = input_shape[0]\n","  input_size = input_shape[1]\n","  n_coords = tf.shape(coords)[1]\n","\n","  coords = tf.clip_by_value(coords, 0, tf.cast(input_size, 'float32') - 1)\n","  coords_lt = tf.cast(tf.floor(coords), 'int32')\n","  #coords_rb = tf.cast(tf.ceil(coords), 'int32')\n","  coords_rb = tf.cast(tf.math.ceil(coords), 'int32')\n","  coords_lb = tf.stack([coords_lt[..., 0], coords_rb[..., 1]], axis=-1)\n","  coords_rt = tf.stack([coords_rb[..., 0], coords_lt[..., 1]], axis=-1)\n","\n","  idx = tf_repeat(tf.range(batch_size), n_coords)\n","\n","  def _get_vals_by_coords(input, coords):\n","      indices = tf.stack([\n","          idx, tf_flatten(coords[..., 0]), tf_flatten(coords[..., 1])\n","      ], axis=-1)\n","      vals = tf.gather_nd(input, indices)\n","      vals = tf.reshape(vals, (batch_size, n_coords))\n","      return vals\n","\n","  vals_lt = _get_vals_by_coords(input, coords_lt)\n","  vals_rb = _get_vals_by_coords(input, coords_rb)\n","  vals_lb = _get_vals_by_coords(input, coords_lb)\n","  vals_rt = _get_vals_by_coords(input, coords_rt)\n","\n","  coords_offset_lt = coords - tf.cast(coords_lt, 'float32')\n","  vals_t = vals_lt + (vals_rt - vals_lt) * coords_offset_lt[..., 0]\n","  vals_b = vals_lb + (vals_rb - vals_lb) * coords_offset_lt[..., 0]\n","  mapped_vals = vals_t + (vals_b - vals_t) * coords_offset_lt[..., 1]\n","\n","  return mapped_vals\n","\n","\n","def sp_batch_map_offsets(input, offsets):\n","  \"\"\"Reference implementation for tf_batch_map_offsets\"\"\"\n","\n","  batch_size = input.shape[0]\n","  input_size = input.shape[1]\n","\n","  offsets = offsets.reshape(batch_size, -1, 2)\n","  grid = np.stack(np.mgrid[:input_size, :input_size], -1).reshape(-1, 2)\n","  grid = np.repeat([grid], batch_size, axis=0)\n","  coords = offsets + grid\n","  coords = coords.clip(0, input_size - 1)\n","\n","  mapped_vals = sp_batch_map_coordinates(input, coords)\n","  return mapped_vals\n","\n","\n","def tf_batch_map_offsets(input, offsets, order=1):\n","  \"\"\"Batch map offsets into input\n","\n","  Parameters\n","  ---------\n","  input : tf.Tensor. shape = (b, s, s)\n","  offsets: tf.Tensor. shape = (b, s, s, 2)\n","\n","  Returns\n","  -------\n","  tf.Tensor. shape = (b, s, s)\n","  \"\"\"\n","\n","  input_shape = tf.shape(input)\n","  batch_size = input_shape[0]\n","  input_size = input_shape[1]\n","\n","  offsets = tf.reshape(offsets, (batch_size, -1, 2))\n","  grid = tf.meshgrid(\n","      tf.range(input_size), tf.range(input_size), indexing='ij'\n","  )\n","  grid = tf.stack(grid, axis=-1)\n","  grid = tf.cast(grid, 'float32')\n","  grid = tf.reshape(grid, (-1, 2))\n","  grid = tf_repeat_2d(grid, batch_size)\n","  coords = offsets + grid\n","\n","  mapped_vals = tf_batch_map_coordinates(input, coords)\n","  return mapped_vals\n","def BN_LeakyReLU(input):\n","    \n","  norm = L.BatchNormalization(axis=-1)(input)\n","  output = L.LeakyReLU(alpha=0.2)(norm)\n","  \n","  return output\n","class ConvOffset2D(Conv2D):\n","  \"\"\"ConvOffset2D\n","\n","  Convolutional layer responsible for learning the 2D offsets and output the\n","  deformed feature map using bilinear interpolation\n","\n","  Note that this layer does not perform convolution on the deformed feature\n","  map. See get_deform_cnn in cnn.py for usage\n","  \"\"\"\n","\n","  def __init__(self, filters, init_normal_stddev=0.01, **kwargs):\n","    \"\"\"Init\n","\n","    Parameters\n","    ----------\n","    filters : int\n","        Number of channel of the input feature map\n","    init_normal_stddev : float\n","        Normal kernel initialization\n","    **kwargs:\n","        Pass to superclass. See Con2D layer in Keras\n","    \"\"\"\n","\n","    self.filters = filters\n","    super(ConvOffset2D, self).__init__(\n","        self.filters * 2, (3, 3), padding='same', use_bias=False,\n","        kernel_initializer=K.initializers.RandomNormal(0, init_normal_stddev),\n","        **kwargs\n","    )\n","\n","  def call(self, x):\n","    \"\"\"Return the deformed featured map\"\"\"\n","    x_shape = x.get_shape()\n","    offsets = super(ConvOffset2D, self).call(x)\n","\n","    # offsets: (b*c, h, w, 2)\n","    offsets = self._to_bc_h_w_2(offsets, x_shape)\n","\n","    # x: (b*c, h, w)\n","    x = self._to_bc_h_w(x, x_shape)\n","\n","    # X_offset: (b*c, h, w)\n","    x_offset = tf_batch_map_offsets(x, offsets)\n","\n","    # x_offset: (b, h, w, c)\n","    x_offset = self._to_b_h_w_c(x_offset, x_shape)\n","\n","    return x_offset\n","\n","  def compute_output_shape(self, input_shape):\n","    \"\"\"Output shape is the same as input shape\n","\n","    Because this layer does only the deformation part\n","    \"\"\"\n","    return input_shape\n","\n","  @staticmethod\n","  def _to_bc_h_w_2(x, x_shape):\n","    \"\"\"(b, h, w, 2c) -> (b*c, h, w, 2)\"\"\"\n","    x = tf.transpose(x, [0, 3, 1, 2])\n","    x = tf.reshape(x, (-1, int(x_shape[1]), int(x_shape[2]), 2))\n","    return x\n","\n","  @staticmethod\n","  def _to_bc_h_w(x, x_shape):\n","    \"\"\"(b, h, w, c) -> (b*c, h, w)\"\"\"\n","    x = tf.transpose(x, [0, 3, 1, 2])\n","    x = tf.reshape(x, (-1, int(x_shape[1]), int(x_shape[2])))\n","    return x\n","\n","  @staticmethod\n","  def _to_b_h_w_c(x, x_shape):\n","    \"\"\"(b*c, h, w) -> (b, h, w, c)\"\"\"\n","    x = tf.reshape(\n","        x, (-1, int(x_shape[3]), int(x_shape[1]), int(x_shape[2]))\n","    )\n","    x = tf.transpose(x, [0, 2, 3, 1])\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Coy8hHLHxsj5"},"source":["######################################backbone部分######################################\n","def feature_extraction_CNN(input_shape, training_parameter= False,n_filters=64):\n","  # X_input=L.Input(input_shape)\n","  conv1 = L.Conv2D(n_filters, (3, 3), padding='same', kernel_initializer='he_normal',\n","                  kernel_regularizer=regularizers.l2(0.0001))(input_shape)\n","  \n","  conv1 = BN_LeakyReLU(conv1)\n","  conv1 = L.Conv2D(2*n_filters, (3, 3), padding='same', kernel_initializer='he_normal',\n","                  kernel_regularizer=regularizers.l2(0.0001))(conv1)\n","  conv1 = BN_LeakyReLU(conv1)\n","  \n","  pool1 = L.MaxPool2D(pool_size=(2, 2),padding='same')(conv1)\n","  # print(pool1)\n","  #可变形block A1\n","  # print(pool1)\n","  offset_conv2_1 = ConvOffset2D(2*n_filters)(pool1)\n","  \n","  conv2_1 = L.Conv2D(n_filters, (3, 3), padding='same', kernel_initializer='he_normal',\n","                  kernel_regularizer=regularizers.l2(0.0001))(offset_conv2_1)\n","  conv2_1 = BN_LeakyReLU(conv2_1)\n","  \n","  offset_conv2_2 = ConvOffset2D(n_filters)(conv2_1)\n","  conv2_2 = L.Conv2D(int(0.5*n_filters), (3, 3), padding='same', kernel_initializer='he_normal',\n","                  kernel_regularizer=regularizers.l2(0.0001))(offset_conv2_2)\n","  conv2_2 = BN_LeakyReLU(conv2_2)\n","  \n","  offset_conv2_3 = ConvOffset2D(int(0.5*n_filters))(conv2_2)\n","  conv2_3 = L.Conv2D(int(0.5*n_filters), (3, 3), padding='same', kernel_initializer='he_normal',\n","                  kernel_regularizer=regularizers.l2(0.0001))(offset_conv2_3)\n","  conv2_3 = BN_LeakyReLU(conv2_3)\n","  \n","  conv2_4 = L.concatenate([conv2_1, conv2_2, conv2_3], axis=-1)\n","  # print(conv2_4)\n","  conv2_5 = L.add([conv2_4, pool1])\n","\n","  #可变形block A2\n","  offset_conv2_6 = ConvOffset2D(2*n_filters)(conv2_5)\n","  conv2_6 = L.Conv2D(n_filters, (3, 3), padding='same', kernel_initializer='he_normal',\n","                  kernel_regularizer=regularizers.l2(0.0001))(offset_conv2_6)\n","  conv2_6 = BN_LeakyReLU(conv2_6)\n","  \n","  offset_conv2_7 = ConvOffset2D(n_filters)(conv2_6)\n","  conv2_7 = L.Conv2D(int(0.5*n_filters), (3, 3), padding='same', kernel_initializer='he_normal',\n","                  kernel_regularizer=regularizers.l2(0.0001))(offset_conv2_7)\n","  conv2_7 = BN_LeakyReLU(conv2_7)\n","  \n","  offset_conv2_8 = ConvOffset2D(int(0.5*n_filters))(conv2_7)\n","  conv2_8 = L.Conv2D(int(0.5*n_filters), (3, 3), padding='same', kernel_initializer='he_normal',\n","                  kernel_regularizer=regularizers.l2(0.0001))(offset_conv2_8)\n","  conv2_8 = BN_LeakyReLU(conv2_8)\n","  \n","  conv2_9 = L.concatenate([conv2_6, conv2_7, conv2_8], axis=-1)\n","  \n","  conv2_10 = L.add([conv2_9, conv2_5])\n","  \n","  \n","  #pool2 = L.MaxPool2D(pool_size=(2, 2),padding='same')(conv2_5)\n","  \n","  conv3 = L.Conv2D(4*n_filters, (3, 3), padding='valid', strides=(2, 2), kernel_initializer='he_normal',\n","                  kernel_regularizer=regularizers.l2(0.0001))(conv2_5)\n","  \n","  offset_conv3_1 = ConvOffset2D(4*n_filters)(conv3)\n","  \n","  conv3_1 = L.Conv2D(2*n_filters, (3, 3), padding='same', kernel_initializer='he_normal',\n","                  kernel_regularizer=regularizers.l2(0.0001))(offset_conv3_1)\n","  conv3_1 = BN_LeakyReLU(conv3_1)\n","  \n","  offset_conv3_2 = ConvOffset2D(2*n_filters)(conv3_1)\n","  conv3_2 = L.Conv2D(n_filters, (3, 3), padding='same', kernel_initializer='he_normal',\n","                  kernel_regularizer=regularizers.l2(0.0001))(offset_conv3_2)\n","  conv3_2 = BN_LeakyReLU(conv3_2)\n","  offset_conv3_3 = ConvOffset2D(n_filters)(conv3_2)\n","  conv3_3 = L.Conv2D(n_filters, (3, 3), padding='same', kernel_initializer='he_normal',\n","                  kernel_regularizer=regularizers.l2(0.0001))(offset_conv3_3)\n","  conv3_3 = BN_LeakyReLU(conv3_3)\n","  \n","  conv3_4 = L.concatenate([conv3_1, conv3_2, conv3_3], axis=-1)\n","  \n","  conv3_5 = L.add([conv3_4, conv3])\n","\n","  #改了一下4*\n","  offset_conv3_6 = ConvOffset2D(n_filters)(conv3_2)\n","  \n","  conv3_6 = L.Conv2D(2*n_filters, (3, 3), padding='same', kernel_initializer='he_normal',\n","                  kernel_regularizer=regularizers.l2(0.0001))(offset_conv3_6)\n","  conv3_6 = BN_LeakyReLU(conv3_6)\n","  \n","  offset_conv3_7 = ConvOffset2D(2*n_filters)(conv3_6)\n","  conv3_7 = L.Conv2D(n_filters, (3, 3), padding='same', kernel_initializer='he_normal',\n","                  kernel_regularizer=regularizers.l2(0.0001))(offset_conv3_7)\n","  conv3_7 = BN_LeakyReLU(conv3_7)\n","  \n","  offset_conv3_8 = ConvOffset2D(n_filters)(conv3_7)\n","  conv3_8 = L.Conv2D(n_filters, (3, 3), padding='same', kernel_initializer='he_normal',\n","                  kernel_regularizer=regularizers.l2(0.0001))(offset_conv3_8)\n","  conv3_8 = BN_LeakyReLU(conv3_8)\n","  \n","  conv3_9 = L.concatenate([conv3_6, conv3_7, conv3_8], axis=-1)\n","  \n","  conv3_10 = L.add([conv3_9, conv3_5])\n","  \n","  \n","  #pool3 = L.MaxPool2D(pool_size=(2, 2),padding='same')(conv3)\n","  #输出128维计算度量\n","  # print(conv3_10)\n","  conv4 = L.Conv2D(n_filters*2, (3, 3), padding='same', kernel_initializer='he_normal',\n","                  kernel_regularizer=regularizers.l2(0.0001))(conv3_10)\n","  # print(conv4)\n","  gap = L.GlobalAvgPool2D()(conv4)\n","  # print(gap)\n","  #增加功能\n","  X = Dense(1024,kernel_regularizer=regularizers.l2(0.01),name='dense_layer1')(gap)\n","  X1 = Dropout(rate=0.5)(X,training=training_parameter)#打开training模式，测试时也使用dropout\n","  X2 = Dense(256,kernel_regularizer=regularizers.l2(0.01),name='dense_layer2')(X1)\n","  X3 = Dropout(rate=0.5)(X2,training=training_parameter)\n","  spatial_result = X3\n","  print('输出向量维度：' + str(spatial_result.shape))\n","  return spatial_result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HTpQoHqcxZo0"},"source":["#预测"]},{"cell_type":"code","metadata":{"id":"apVJSnI1mdVB"},"source":["def read_image(filename):\n","  img = tiff.imread(filename)\n","  # img = cv2.imread(filename,-1)\n","  # img = np.asarray(img, dtype=np.float32)\n","  return img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Ud0StlgUGap"},"source":["def Patch(data, height_index, width_index):\n","  \n","  height_slice = slice(height_index-r, height_index + r+1)\n","  width_slice = slice(width_index-r, width_index + r+1)\n","  patch = data[height_slice, width_slice, :]\n","  \n","  return patch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L1IJ7-iNmnHa"},"source":["def sample_normalization(data):\n","    \"\"\"\n","    normalize each sample to 0-1\n","    Input:\n","        sample\n","    Output:\n","        Normalized sample\n","    \"\"\"\n","    if np.max(data) == np.min(data):\n","        return np.ones_like(data, dtype=np.float32) * 1e-6\n","    else:\n","        return 1.0 * (data - np.min(data)) / (np.max(data) - np.min(data))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lPa35pkTmBMH"},"source":["#判断是否背景值\n","def judge_underground(img,height,width):\n","  # print(Counter(img[height,width,:]))\n","  if Counter(img[height,width,:])[0] == 12:\n","    return True\n","  else:\n","    return False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"24hV-VdTh__3"},"source":["def get_patch(data,height_index,width_index,r=7):\n","  patch = data[height_index-r:height_index+r+1,width_index-r:width_index+r+1,:]\n","  return patch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zAAAizlSPp8l"},"source":["#大图切片预测"]},{"cell_type":"code","metadata":{"id":"7S9h8CXpfVFq"},"source":["datapath = '/content/gdrive/MyDrive/CM/img/zhangbei_subset.tif'\n","r=7\n","hchn = 12\n","PATCH_SIZE = 15\n","step = 1  # 每隔几个像素预测一次，如果每个像素都预测，则 step 为 1\n","NUM_CLASS = 7"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R6IGh3JaYB7x"},"source":["def predict_little(img,mean,model):\n","  height, width, channel = img.shape\n","  # img=np.pad(img,((r,r),(r,r),(0,0)),'symmetric')\n","  outputs = np.zeros((height, width))\n","  # print('\\n输入patch大小为:',img.shape)\n","  # print('输出patch大小为：',outputs[r:height-r,r:width-r].shape)\n","  for i in range(r, height-r, step):\n","    for j in range(r, width-r, step):\n","      if judge_underground(img,i,j) == False:\n","        # print(img[i,j,:])\n","        image_patch = Patch(img, i, j)  # 切 patch\n","        #巨大BUG！忘了已经归一化过了\n","        # image_patch = sample_normalization(image_patch)\n","        image_patch = image_patch - mean\n","        X_test_image = image_patch[np.newaxis,...]\n","        \n","        # count += 1\n","        # # if count%1000 == 0:\n","        # #     print('step={}'.format(count))\n","        pred = (np.argmax(model.predict(X_test_image)))\n","        # #pred_cls = np.argmax(pred, axis=1)\n","        pred_num = np.asarray(pred, dtype=np.int8)\n","        outputs[i,j] = pred_num\n","        \n","        # # outputs[i+int(PATCH_SIZE/2)][j+int(PATCH_SIZE/2)] = pred_num  # 原始代码\n","        # outputs[i//step][j//step] = pred_num\n","      else:\n","        outputs[i,j] = 0\n","  return outputs[r:height-r,r:width-r]\n","def splitpredict(path,model):\n","  img = read_image(path)\n","  height, width, channel = img.shape\n","  img = sample_normalization(img)\n","  mean_value = np.mean(img)\n","  h_step = img.shape[0] // 256\n","  w_step = img.shape[1] // 256\n","  h_last = img.shape[0] % 256\n","  w_last = img.shape[1] % 256\n","  # outputs = np.zeros((height, width))\n","  #循环切图\n","  # plt.figure()\n","  for h in tqdm(range(17,18),position=0):\n","    for w in tqdm(range(24,25),position=0):\n","      if (w < w_step - 1 and w > 0) and ( h > 0 and h < h_step -1):#内部\n","        image_sample = img[(h * 256 - r):(h * 256 + 256 + r),(w * 256 - r):(w * 256 + 256 + r), :]\n","        # print('内部',image_sample.shape)\n","\n","      elif (w==0) and (h==0): #左上边界\n","        image_sample = img[0:256+r,0:256+r, :]\n","        image_sample = np.pad(image_sample,((r,0),(r,0),(0,0)),'symmetric')\n","        # print('左上',image_sample.shape)\n","\n","      elif ( w==0 ) and (h < h_step -1):#左边界\n","        image_sample = img[(h * 256 - r):(h * 256 + 256 + r),0:256+r, :]\n","        image_sample = np.pad(image_sample,((0,0),(r,0),(0,0)),'symmetric')\n","        # print('左边界',image_sample.shape)\n","\n","      elif (w < w_step -1) and (h == 0 ): #上边界\n","        image_sample = img[0:256+r,(w * 256 - r):(w * 256 + 256 + r), :]\n","        image_sample = np.pad(image_sample,((r,0),(0,0),(0,0)),'symmetric')\n","        # print('上边界',image_sample.shape)\n","\n","      elif ( w == w_step - 1) and (h ==0):#右上边界\n","        image_sample = img[0:256+r,(w * 256 - r):(w * 256 + w_last), :]\n","        image_sample = np.pad(image_sample,((r,0),(0,0),(0,0)),'symmetric')\n","        # print('右上边界',image_sample.shape)\n","\n","      elif (w == w_step -1) and (h < h_step -1):#右边界\n","        image_sample = img[(h * 256 - r):(h * 256 + 256 + r),(w * 256 - r):(w * 256 + w_last), :]\n","        # print('右边界',image_sample.shape)\n","\n","      elif (w < w_step - 1 and w > 0) and (h == h_step -1):#下边界\n","        image_sample = img[(h * 256 - r):(h * 256 + h_last),(w * 256 - r):(w * 256 + 256 + r), :]\n","        # print('下边界',image_sample.shape)\n","\n","      elif (w == 0) and (h == h_step -1):#左下边界\n","        image_sample = img[(h * 256 - r):(h * 256 + h_last),0:(w * 256 + 256 + r), :]\n","        image_sample = np.pad(image_sample,((0,0),(r,0),(0,0)),'symmetric')\n","        # print('左下边界',image_sample.shape)\n","\n","      else:#右下边界\n","        image_sample = img[(h * 256 - r):(h * 256 + h_last),(w * 256 - r):(w * 256 + w_last), :]\n","        # print('右下边界',image_sample.shape)\n","\n","      pred_little = predict_little(image_sample,mean_value,model)\n","      np.save('/content/gdrive/MyDrive/CM/RSL/paperimage_cut/cut_'+str(h)+'_'+str(w), pred_little)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DW9rUGFopWn8","executionInfo":{"elapsed":4777,"status":"ok","timestamp":1623979927507,"user":{"displayName":"Boan Chen","photoUrl":"","userId":"13891223129202903233"},"user_tz":-480},"outputId":"79ffe731-c963-4026-bdcd-0c42050bf79a"},"source":["model1 = import_model('/content/gdrive/MyDrive/CM/RSL/CE_highsoftmx_highmix_lowups4.h5',train_para = False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["输出向量维度：(None, 256)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"86v1JhQGUg0D","executionInfo":{"status":"ok","timestamp":1623981922313,"user_tz":-480,"elapsed":145509,"user":{"displayName":"Boan Chen","photoUrl":"","userId":"13891223129202903233"}},"outputId":"d5100f0a-85d7-46ef-9f53-776ad65bdbe4"},"source":["splitpredict(datapath,model1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 1/1 [32:38<00:00, 1958.11s/it]\n","100%|██████████| 1/1 [32:38<00:00, 1958.12s/it]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"A8dxvLxbZnyU"},"source":["#拼接保存图\n"]},{"cell_type":"code","metadata":{"id":"quiPnt4yadQv"},"source":["cv2.imwrite(\"/content/gdrive/MyDrive/CM/RSL/paperimage/zhangbei.png\", predict_image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BmqBC_lWbZCx"},"source":["os.chdir('/content/gdrive/MyDrive/CM/RSL/paperimage_cut')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4pYWl3Oy0RgJ"},"source":["#拼接图片\n","for i in range(31):\n","  result  = np.load('cut_'+str(i)+'_0.npy')\n","  for j in tqdm(range(1,43),position=0):\n","    filepath = 'cut_'+str(i)+'_'+str(j)+'.npy'\n","    patch = np.load(filepath)\n","    result = np.concatenate([result, patch], axis=1)\n","  np.save('cut_'+str(i)+'.npy', result)\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8LNvpZjk5jFT"},"source":["result  = np.load('cut_0.npy')\n","for i in range(1,31):\n","  filepath = 'cut_'+str(i)+'.npy'\n","  patch = np.load(filepath)\n","  result = np.concatenate([result, patch], axis=0)\n","np.save('zhangbei_map.npy', result)"],"execution_count":null,"outputs":[]}]}